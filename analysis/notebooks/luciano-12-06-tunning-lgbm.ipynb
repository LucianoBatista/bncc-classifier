{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic tools\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# building models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import shap\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_parameter_opt_lgb(\n",
    "    X,\n",
    "    y,\n",
    "    init_round=15,\n",
    "    opt_round=25,\n",
    "    n_folds=3,\n",
    "    random_seed=6,\n",
    "    n_estimators=10000,\n",
    "    output_process=False,\n",
    "):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(\n",
    "        learning_rate,\n",
    "        num_leaves,\n",
    "        feature_fraction,\n",
    "        bagging_fraction,\n",
    "        max_depth,\n",
    "        max_bin,\n",
    "        min_data_in_leaf,\n",
    "        min_sum_hessian_in_leaf,\n",
    "        subsample,\n",
    "    ):\n",
    "        params = {\"application\": \"binary\", \"metric\": \"auc\"}\n",
    "        params[\"learning_rate\"] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params[\"feature_fraction\"] = max(min(feature_fraction, 1), 0)\n",
    "        params[\"bagging_fraction\"] = max(min(bagging_fraction, 1), 0)\n",
    "        params[\"max_depth\"] = int(round(max_depth))\n",
    "        params[\"max_bin\"] = int(round(max_depth))\n",
    "        params[\"min_data_in_leaf\"] = int(round(min_data_in_leaf))\n",
    "        params[\"min_sum_hessian_in_leaf\"] = min_sum_hessian_in_leaf\n",
    "        params[\"subsample\"] = max(min(subsample, 1), 0)\n",
    "\n",
    "        cv_result = lgb.cv(\n",
    "            params,\n",
    "            train_data,\n",
    "            nfold=n_folds,\n",
    "            seed=random_seed,\n",
    "            stratified=True,\n",
    "            verbose_eval=200,\n",
    "            metrics=[\"auc\"],\n",
    "        )\n",
    "        return max(cv_result[\"auc-mean\"])\n",
    "\n",
    "    lgbBO = BayesianOptimization(\n",
    "        lgb_eval,\n",
    "        {\n",
    "            \"learning_rate\": (0.01, 1.0),\n",
    "            \"num_leaves\": (24, 80),\n",
    "            \"feature_fraction\": (0.1, 0.9),\n",
    "            \"bagging_fraction\": (0.8, 1),\n",
    "            \"max_depth\": (5, 30),\n",
    "            \"max_bin\": (20, 90),\n",
    "            \"min_data_in_leaf\": (20, 80),\n",
    "            \"min_sum_hessian_in_leaf\": (0, 100),\n",
    "            \"subsample\": (0.01, 1.0),\n",
    "        },\n",
    "        random_state=200,\n",
    "    )\n",
    "\n",
    "    # n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    # init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "\n",
    "    model_auc = []\n",
    "    for model in range(len(lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model][\"target\"])\n",
    "\n",
    "    # return best parameters\n",
    "    return (\n",
    "        lgbBO.res[pd.Series(model_auc).idxmax()][\"target\"],\n",
    "        lgbBO.res[pd.Series(model_auc).idxmax()][\"params\"],\n",
    "    )\n",
    "\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(\n",
    "    X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6, n_estimators=10000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
